{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Grid post-processing of Met.no data using SHyFT API\n",
    "=========\n",
    "\n",
    "### This notebook gives an example of Met.no data post-processing to correct temperature forecasts based on comparison to observations. The following steps are described:\n",
    "1. **Loading required python modules and setting path to SHyFT installation**\n",
    "2. **Create synthetic data for observation time-series**\n",
    "3. **Create synthetic data for forecast time-series**\n",
    "4. **Calculate correction bias between observations and forecasts**\n",
    "5. **Apply bias correction to forecast time-series**\n",
    "6. **Plot the results**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading required python modules and setting path to SHyFT installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first you should import the third-party python modules which you'll use later on\n",
    "# the first line enables that figures are shown inline, directly in the notebook\n",
    "%pylab inline\n",
    "import os\n",
    "from os import path\n",
    "import sys\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set the path for your shyft build\n",
    "# this should point to the directory that is created\n",
    "# when you clone shyft, assuming you have built shyft\n",
    "# there and not installed it to your system python\n",
    "shyft_path = os.path.abspath(\"../../../shyft\")\n",
    "sys.path.insert(0, shyft_path)\n",
    "\n",
    "# you could achieve the same by setting a PYTHONPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# once the shyft_path is set correctly, you should be able to import shyft modules\n",
    "import shyft\n",
    "from shyft import shyftdata_dir\n",
    "\n",
    "# if you have problems here, it may be related to having your LD_LIBRARY_PATH\n",
    "# pointing to the appropriate libboost_python libraries (.so files)\n",
    "from shyft.repository.default_state_repository import DefaultStateRepository\n",
    "from shyft.orchestration.configuration import yaml_configs\n",
    "from shyft.orchestration.simulators.config_simulator import ConfigSimulator\n",
    "from shyft import api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now you can access the api of shyft with tab completion and help, try this:\n",
    "\n",
    "#help(api.GeoPoint) # remove the hashtag and run the cell to print the documentation of the api.GeoPoint class\n",
    "#api. # remove the hashtag, set the pointer behind the dot and use \n",
    "      # tab completion to see the available attributes of the shyft api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create synthetic data for observation time-series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create time-axis starting 01.01.2016, sampled every hour for 10 days long\n",
    "t0 = api.Calendar().time(2016, 1, 1)\n",
    "ta = api.Timeaxis(t0, api.deltahours(1), 240)\n",
    "ta2 = api.Timeaxis2(t0, api.deltahours(1), 240)\n",
    "\n",
    "# Create a set of geo-locations at observation points (sparse set covering the forecast grid)\n",
    "obs_locs = api.GeoPointVector()\n",
    "obs_locs.append(api.GeoPoint( 100, 100,   10))\n",
    "obs_locs.append(api.GeoPoint(5100, 100,  250))\n",
    "obs_locs.append(api.GeoPoint( 100, 5100, 250))\n",
    "obs_locs.append(api.GeoPoint(5100, 5100, 500))\n",
    "\n",
    "# Create a set of time-series at observation points, having constant value\n",
    "obs_set = api.GeoPointSourceVector()\n",
    "for loc in obs_locs:\n",
    "    obs_set.append(api.GeoPointSource(loc, api.Timeseries(ta2, fill_value=10)))\n",
    "\n",
    "# Create a set of geo-locations at forecast points (evenly spaced grid of 10 x 10 km)\n",
    "fc_locs = api.GeoPointVector()\n",
    "for x in range(10):\n",
    "    for y in range(10):\n",
    "        fc_locs.append(api.GeoPoint(x*1000, y*1000, (x+y)*50))\n",
    "\n",
    "# Spread the set of observations to forecast locations by ordinary Kriging\n",
    "obs_grid = api.ordinary_kriging(obs_set, fc_locs, ta, api.OKParameter())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create synthetic data for forecast time-series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create an empty forecast grid\n",
    "fc_grid = api.PrecipitationSourceVector()\n",
    "\n",
    "# Create a synthetic bias time-serie\n",
    "bias_ts = api.Timeseries(ta2, fill_value=1)\n",
    "\n",
    "# Create forecast time-series by adding the synthetic bias to the observation time-series\n",
    "for obs in obs_grid:\n",
    "    fc_grid.append(api.PrecipitationSource(obs.mid_point(), obs.ts + bias_ts))\n",
    "\n",
    "# Create a forecast set to observation locations by IDW transform\n",
    "fc_set = api.idw_precipitation(fc_grid, obs_locs, ta, api.IDWPrecipitationParameter())\n",
    "\n",
    "# Check that the grid mapping matches the observation locations (less than 5% error is fine)\n",
    "is_good = abs(fc_set[0].ts.value(0) - fc_grid[0].ts.value(0)) < 0.05\n",
    "print('Is mapping good? ' + str(is_good))\n",
    "if not is_good:\n",
    "    print('Forecast at forecast location = ' + str(fc_grid[0].ts.value(0)))\n",
    "    print('Forecast at observation location = ' + str(fc_set[0].ts.value(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Calculate correction bias between observations and forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create an empty bias set\n",
    "bias_set = api.GeoPointSourceVector()\n",
    "\n",
    "# Calculate the bias as a correction factor between observation and forecast timeseries at observation locations\n",
    "for (obs, fc) in zip(obs_set, fc_set):\n",
    "    bias_set.append(api.GeoPointSource(obs.mid_point(), obs.ts / fc.ts))\n",
    "    \n",
    "# Spread the bias from observation locations to forecast locations by ordinary kriging\n",
    "bias_grid = api.ordinary_kriging(bias_set, fc_locs, ta, api.OKParameter())\n",
    "\n",
    "print('The correction factor at the first forecast location is {0:.3f}'.format(bias_grid[0].ts.value(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Apply bias correction to forecast time-series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Apply bias correction to forecast time-series at forecast locations\n",
    "for (fc, bias) in zip(fc_grid, bias_grid):\n",
    "    fc.ts = fc.ts * bias.ts\n",
    "\n",
    "# Transform corrected forecasts to observation locations by IDW transform\n",
    "fc_set = api.idw_precipitation(fc_grid, obs_locs, ta, api.IDWPrecipitationParameter())\n",
    "\n",
    "# Check corrected forecast vs observation \n",
    "is_good = abs(fc_set[0].ts.value(0) - obs_set[0].ts.value(0)) < 0.05\n",
    "print('Is correction good? ' + str(is_good))\n",
    "if not is_good:\n",
    "    print('Observation at observation location = ' + str(obs_set[0].ts.value(0)))\n",
    "    print('Forecast at observation location = ' + str(fc_set[0].ts.value(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make a time-series plot\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "for i in range(len(bias_set)):\n",
    "    timestamps = [datetime.datetime.utcfromtimestamp(p.start) for p in obs_set[i].ts.time_axis]\n",
    "    ax.plot(timestamps, obs_set[i].ts.values, label = str(i+1) + ' Observation')\n",
    "    ax.plot(timestamps, fc_set[i].ts.values, label = str(i+1) + ' Forecast')\n",
    "    ax.plot(timestamps, bias_set[i].ts.values, label = str(i+1) + ' Bias')\n",
    "fig.autofmt_xdate()\n",
    "ax.legend(title='Precipitation')\n",
    "ax.set_ylabel('Precipitation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make a scatter plot of grid temperature forecasts at ts.value(0)\n",
    "x = [fc.mid_point().x for fc in fc_grid]\n",
    "y = [fc.mid_point().y for fc in fc_grid]\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "temps = np.array([fc.ts.value(0) for fc in fc_grid])\n",
    "plot = ax.scatter(x, y, c=temps, marker='s', vmin=0, vmax=12, s=500, lw=0)\n",
    "plt.colorbar(plot).set_label('Precipitation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(15,5))\n",
    "temps = np.array([fc.ts.value(0) for fc in fc_grid])\n",
    "ax1.scatter(x, y, c=temps, marker='s', vmin=0, vmax=20, s=500, lw=0)\n",
    "temps = np.array([obs.ts.value(0) for obs in bias_grid])\n",
    "ax2.scatter(x, y, c=temps, marker='s', vmin=0, vmax=20, s=500, lw=0)\n",
    "#plt.colorbar(plot).set_label('Precipitation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
