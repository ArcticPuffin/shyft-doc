{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Grid post-processing of Met.no data using SHyFT API\n",
    "\n",
    "\n",
    "#### This notebook gives an example of Met.no data post-processing to correct temperature forecasts based on comparison to observations. The following steps are described:\n",
    "1. **Loading required python modules and setting path to SHyFT installation**\n",
    "\n",
    "Setup steps is about creating synthetic data, and backtesting those\n",
    "so that we have a known forecast that gives a certain response at the\n",
    "four observation points\n",
    "\n",
    "1. **Generate synthetic data for temperature observation time-series**\n",
    "2. **Transform observations from set to grid (Kriging)**\n",
    "3. **Create 3 forecasts sets for the 1x1 km grid **\n",
    "\n",
    "grid-pp steps is about orchestrating a grid-pp algorithm given\n",
    "our syntethic data from above\n",
    "\n",
    "1. **Transform forecasts from grid to observation points (IDW)**\n",
    "2. **Calculate the bias time-series using Kalman filter on the difference of observation and forecast set at the observation points**\n",
    "3. **Transform bias from set to grid (Kriging) and apply bias to the grid forecast**\n",
    "\n",
    "Final steps to plot and test the results from the grid-pp steps\n",
    "\n",
    "1. **Transform corrected forecasts grid to the observation points (IDW)**\n",
    "2. **Plot the results and bias**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading required python modules and setting path to SHyFT installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first you should import the third-party python modules which you'll use later on\n",
    "# the first line enables that figures are shown inline, directly in the notebook\n",
    "%pylab inline\n",
    "import os\n",
    "from os import path\n",
    "import sys\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set the path for your shyft build\n",
    "# this should point to the directory that is created\n",
    "# when you clone shyft, assuming you have built shyft\n",
    "# there and not installed it to your system python\n",
    "shyft_path = os.path.abspath(\"../../../shyft\")\n",
    "sys.path.insert(0, shyft_path)\n",
    "\n",
    "# you could achieve the same by setting a PYTHONPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# once the shyft_path is set correctly, you should be able to import shyft modules\n",
    "import shyft\n",
    "from shyft import shyftdata_dir\n",
    "\n",
    "# if you have problems here, it may be related to having your LD_LIBRARY_PATH\n",
    "# pointing to the appropriate libboost_python libraries (.so files)\n",
    "from shyft.repository.default_state_repository import DefaultStateRepository\n",
    "from shyft.orchestration.configuration import yaml_configs\n",
    "from shyft.orchestration.simulators.config_simulator import ConfigSimulator\n",
    "from shyft.api import Calendar\n",
    "from shyft.api import deltahours\n",
    "from shyft.api import Timeaxis,Timeaxis2\n",
    "from shyft.api import Timeseries\n",
    "from shyft.api import time_shift\n",
    "from shyft.api import TemperatureSource\n",
    "from shyft.api import TemperatureSourceVector\n",
    "from shyft.api import GeoPoint\n",
    "from shyft.api import GeoPointVector\n",
    "from shyft.api import bayesian_kriging_temperature\n",
    "from shyft.api import BTKParameter\n",
    "from shyft.api import idw_temperature\n",
    "from shyft.api import IDWTemperatureParameter\n",
    "from shyft.api import KalmanFilter\n",
    "from shyft.api import KalmanState\n",
    "from shyft.api import KalmanBiasPredictor\n",
    "from shyft.api import create_periodic_pattern_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now you can access the api of shyft with tab completion and help, try this:\n",
    "\n",
    "#help(api.GeoPoint) # remove the hashtag and run the cell to print the documentation of the api.GeoPoint class\n",
    "#api. # remove the hashtag, set the pointer behind the dot and use \n",
    "      # tab completion to see the available attributes of the shyft api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup: 1. Generate synthetic data for temperature observation time-series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create time-axis for our syntethic sample\n",
    "utc = Calendar() # provide conversion and math for utc time-zone\n",
    "t0 = utc.time(2016, 1, 1)\n",
    "dt = deltahours(1)\n",
    "n = 24*3 # 3 days length\n",
    "ta = Timeaxis(t0, dt, n)\n",
    "ta2 = Timeaxis2(t0, dt, n) # same as ta, but needed for now(we work on aligning them)\n",
    "\n",
    "# 1. Create the terrain based geo-points for the 1x1km grid and the observations\n",
    "\n",
    "# a. Create the grid, based on a syntethic terrain model\n",
    "# specification of 1 x 1 km\n",
    "grid_1x1 = GeoPointVector()\n",
    "for x in range(10):\n",
    "    for y in range(10):\n",
    "        grid_1x1.append(GeoPoint(x*1000, y*1000, (x+y)*50)) # z from 0 to 1000 m\n",
    "\n",
    "# b. Create the observation points, for metered temperature\n",
    "# reasonable withing that grid_1x1, and with elevation z\n",
    "# that corresponds approximately to the position\n",
    "obs_points = GeoPointVector()\n",
    "obs_points.append(GeoPoint( 100, 100, 10))  # observation point at the lowest part\n",
    "obs_points.append(GeoPoint(5100, 100, 270 )) # halfway out in x-direction @ 270 masl\n",
    "obs_points.append(GeoPoint( 100, 5100, 250)) # halfway out in y-direction @ 250 masl\n",
    "obs_points.append(GeoPoint(10100,10100, 1080 )) # x-y at max, so @1080 masl\n",
    "\n",
    "# 2. Create time-series having a constant temperature of 15 degC\n",
    "#    and add them to the syntetic observation set\n",
    "#    make sure there is some reality, like temperature gradient etc.\n",
    "ts = Timeseries(ta2, fill_value=20.0)  # 20 degC at z_t= 0 meter above sea-level\n",
    "# assume set temp.gradient to -0.6 degC/100m, and estimate the other values accordingly                                                   \n",
    "tgrad = -0.6/100.0  # in our case in units of degC/m\n",
    "z_t = 0 # meter above sea-level\n",
    "\n",
    "# Create a TemperatureSourceVector to hold the set of observation time-series\n",
    "constant_bias=[-1.0,-0.6,0.7,+1.0]\n",
    "obs_set = TemperatureSourceVector()\n",
    "obs_set_w_bias = TemperatureSourceVector()\n",
    "for geo_point,bias in zip(obs_points,constant_bias):\n",
    "    temp_at_site =  ts + tgrad*(geo_point.z-z_t)\n",
    "    obs_set.append(TemperatureSource(geo_point,temp_at_site))\n",
    "    obs_set_w_bias.append(TemperatureSource(geo_point,temp_at_site + bias))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup 2. Transform observation with bias to grid using kriging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate the observation grid by kriging the observations out to 1x1km grid\n",
    "# first create idw and kriging parameters that we will utilize in the next steps\n",
    "# kriging parameters\n",
    "btk_params = BTKParameter()  # we could tune parameters here if needed\n",
    "# idw parameters,somewhat adapted to the fact that we\n",
    "#  know we interpolate from a grid, with a lot of neigbours around\n",
    "idw_params = IDWTemperatureParameter() # here we could tune the paramete if needed\n",
    "idw_params.max_distance = 20*1000.0 # max at 10 km because we search for max-gradients\n",
    "idw_params.max_members = 20 # for grid, this include all possible close neighbors\n",
    "idw_params.gradient_by_equation = True # resolve horisontal component out \n",
    "# now use kriging for our 'syntethic' observations with bias\n",
    "obs_grid = bayesian_kriging_temperature(obs_set_w_bias,grid_1x1,ta,btk_params)\n",
    "\n",
    "\n",
    "# if we idw/btk back to the sites, we should have something that equals the with_bias:\n",
    "# we should get close to zero differences in this to-grid-and-back operation\n",
    "back_test = idw_temperature(obs_grid, obs_points, ta, idw_params)\n",
    "for bt,wb in zip(back_test,obs_set_w_bias):\n",
    "    print(\"IDW Diff {} : {} \".format(bt.mid_point(),abs((bt.ts-wb.ts).values.to_numpy()).max()))\n",
    "    \n",
    "#back_test = bayesian_kriging_temperature(obs_grid, obs_points, ta, btk_params)\n",
    "#for bt,wb in zip(back_test,obs_set_w_bias):\n",
    "#    print(\"BTK Diff {} : {} \".format(bt.mid_point(),abs((bt.ts-wb.ts).values.to_numpy()).max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup 3. Create 3 forecasts sets for the 1x1 km grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a forecast grid by copying the obs_grid time-series\n",
    "# since we know that idw of them to obs_points will give approx.\n",
    "#  the obs_set_w_bias time-series\n",
    "#  for the simplicity, we assume the same forecast for all 3 days\n",
    "\n",
    "fc_grid = TemperatureSourceVector()\n",
    "fc_grid_1_day_back = TemperatureSourceVector() # this is previous day\n",
    "fc_grid_2_day_back = TemperatureSourceVector()  # this is fc two days ago\n",
    "one_day_back_dt = deltahours(-24)\n",
    "two_days_back_dt = deltahours(-24*2)\n",
    "noise_bias = [0.0,0.0,0.0,0.0] # we could generate white noise ts into these to test kalman\n",
    "for fc,bias in zip(obs_grid,noise_bias):\n",
    "    fc_grid.append(TemperatureSource(fc.mid_point(),fc.ts + bias ))\n",
    "    fc_grid_1_day_back.append(\n",
    "        TemperatureSource(\n",
    "                fc.mid_point(),\n",
    "                time_shift(fc.ts + bias, one_day_back_dt) #time-shift the signal back\n",
    "            )\n",
    "        )\n",
    "    fc_grid_2_day_back.append(\n",
    "        TemperatureSource(\n",
    "                fc.mid_point(),\n",
    "                time_shift(fc.ts + bias, two_days_back_dt)\n",
    "            )\n",
    "        )\n",
    "\n",
    "grid_forecasts = [fc_grid_2_day_back, fc_grid_1_day_back, fc_grid ] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### grid-pp: 1. Transform forecasts from grid to observation points (IDW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now we have 3 simulated forecasts at a 1x1 km grid\n",
    "# fc_grid, fc_grid_1_day_back, fc_grid_2_day_back\n",
    "# we start to do the grid pp algorithm stuff\n",
    "# - we know the our forecasts have some degC. bias, and we would hope that\n",
    "#   the kalman filter 'learns' the offset\n",
    "# as a first step we project the grid_forecasts to the observation points\n",
    "# making a list of historical forecasts at each observation point.\n",
    "\n",
    "fc_at_observation_points = [idw_temperature(fc, obs_points, ta, idw_params)\\\n",
    "                            for fc in grid_forecasts]\n",
    "historical_forecasts = []\n",
    "for i in range(len(obs_points)):  # correlate obs.point and fc using common i\n",
    "    fc_list = TemperatureSourceVector()  # the kalman bias predictor below accepts TsVector of forecasts\n",
    "    for fc in fc_at_observation_points:\n",
    "        fc_list.append(fc[i]) # pick out the fc_ts only, for the i'th observation point\n",
    "        #print(\"{} adding fc pt {} t0={}\".format(i,fc[i].mid_point(),utc.to_string(fc[i].ts.time(0))))\n",
    "    historical_forecasts.append(fc_list)\n",
    "# historical_forecasts  now cntains 3 forecasts for each observation point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### grid-pp: 2. Calculate the bias time-series using Kalman filter on the observation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a TemperatureSourceVector to hold the set of bias time-series\n",
    "bias_set = TemperatureSourceVector()\n",
    "\n",
    "# Create the Kalman filter having 8 samples spaced every 3 hours to represent a daily periodic pattern\n",
    "\n",
    "kalman_dt_hours = 3\n",
    "kalman_dt =deltahours(kalman_dt_hours)\n",
    "kta = Timeaxis2(t0, kalman_dt, int(24//kalman_dt_hours))\n",
    "\n",
    "# Calculate the coefficients of Kalman filter and \n",
    "# Create bias time-series based on the daily periodic pattern\n",
    "for i in range(len(obs_set)):\n",
    "    kf = KalmanFilter() # each observation location do have it's own kf &predictor\n",
    "    kbp = KalmanBiasPredictor(kf)\n",
    "    #print(\"Diffs for obs\", i)\n",
    "    #for fc in historical_forecasts[i]:\n",
    "    #    print((fc.ts-obs_set[i].ts).values.to_numpy())\n",
    "    kbp.update_with_forecast(historical_forecasts[i], obs_set[i].ts, kta)\n",
    "    pattern = KalmanState.get_x(kbp.state)\n",
    "    #print(pattern)\n",
    "    bias_ts = create_periodic_pattern_ts(pattern, kalman_dt, ta.time(0), ta2)\n",
    "    bias_set.append(TemperatureSource(obs_set[i].mid_point(), bias_ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### grid-pp: 3. Spread the bias at observation points out to the grid using kriging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate the bias grid by kriging the bias out on the 1x1km grid\n",
    "btk_params = BTKParameter()\n",
    "btk_bias_params = BTKParameter(temperature_gradient=-0.6, temperature_gradient_sd=0.25, sill=25.0, nugget=0.5, range=5000.0, zscale=20.0)\n",
    "bias_grid =  bayesian_kriging_temperature(bias_set, grid_1x1, ta, btk_bias_params)\n",
    "# Correct forecasts by applying bias time-series on the grid\n",
    "fc_grid_improved = TemperatureSourceVector()\n",
    "for i in range(len(fc_grid)):\n",
    "    fc_grid_improved.append(\n",
    "        TemperatureSource(\n",
    "            fc_grid[i].mid_point(),\n",
    "            fc_grid[i].ts - bias_grid[i].ts # By convention, sub bias time-series(hmm..)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check the first value of the time-series. It should be around 15\n",
    "tx =ta.time(0)\n",
    "print(\"Comparison original synthetic grid cell [0]\\n\\t at the lower left corner,\\n\\t at t {}\\n\\toriginal grid: {}\\n\\timproved grid: {}\\n\\t vs bias grid: {}\\n\\t nearest obs: {}\"\n",
    "      .format(utc.to_string(tx),\n",
    "              fc_grid[0].ts(tx),\n",
    "              fc_grid_improved[0].ts(tx),\n",
    "              bias_grid[0].ts(tx),\n",
    "              obs_set[0].ts(tx)\n",
    "             )\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Presentation&Test: 8. Finally, Transform corrected forecasts from grid to  observation points to see if we did reach the goal of adjusting the forecast (IDW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate the corrected forecast set by Krieging transform of temperature model\n",
    "fc_at_observations_improved = idw_temperature(fc_grid_improved, obs_points, ta, idw_params)\n",
    "fc_at_observations_raw =idw_temperature(fc_grid, obs_points, ta, idw_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make a time-series plot of temperature sets\n",
    "for i in range(len(bias_set)):\n",
    "    fig, ax = plt.subplots(figsize=(20, 10))\n",
    "    timestamps = [datetime.datetime.utcfromtimestamp(p.start) for p in obs_set[i].ts.time_axis]\n",
    "    ax.plot(timestamps, obs_set[i].ts.values, label = str(i+1) + ' Observation')\n",
    "    ax.plot(timestamps, fc_at_observations_improved[i].ts.values, label = str(i+1) + ' Forecast improved')\n",
    "    ax.plot(timestamps, fc_at_observations_raw[i].ts.values,linestyle='--', label = str(i+1) + ' Forecast (raw)')\n",
    "    #ax.plot(timestamps, bias_set[i].ts.values, label = str(i+1) + ' Bias')\n",
    "    fig.autofmt_xdate()\n",
    "    ax.legend(title='Temperature')\n",
    "    ax.set_ylabel('Temp ($^\\circ$C)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make a scatter plot of grid temperature forecasts at ts.value(0)\n",
    "x = [fc.mid_point().x for fc in bias_grid]\n",
    "y = [fc.mid_point().y for fc in bias_grid]\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "temps = np.array([bias.ts.value(0) for bias in bias_grid])\n",
    "plot = ax.scatter(x, y, c=temps, marker='o', s=500, lw=0)\n",
    "plt.colorbar(plot).set_label('Temp bias correction ($^\\circ$C)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
